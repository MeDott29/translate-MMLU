{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\nfrom huggingface_hub import login\nlogin(token=f\"{secret_value_0}\",write_permission=True)  # Enter your HF token when prompted\n!pip install sacrebleu pandas tqdm","metadata":{"execution":{"iopub.status.busy":"2024-10-25T06:44:17.470001Z","iopub.execute_input":"2024-10-25T06:44:17.470337Z","iopub.status.idle":"2024-10-25T06:44:31.016375Z","shell.execute_reply.started":"2024-10-25T06:44:17.470303Z","shell.execute_reply":"2024-10-25T06:44:31.015114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import MarianMTModel, MarianTokenizer\nfrom typing import List, Dict\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass TranslationPipeline:\n    def __init__(self):\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        print(f\"Using device: {self.device}\")\n        \n        # Initialize English -> Lojban model\n        print(\"Loading English -> Lojban model...\")\n        self.en_loj_model_name = \"woctordho/lojban-translation\"\n        self.en_loj_tokenizer = MarianTokenizer.from_pretrained(self.en_loj_model_name)\n        self.en_loj_model = MarianMTModel.from_pretrained(self.en_loj_model_name).to(self.device)\n        \n        # Initialize Lojban -> English model\n        print(\"Loading Lojban -> English model...\")\n        self.loj_en_model_name = \"woctordho/lojban-translation\"  # Using reverse model\n        self.loj_en_tokenizer = MarianTokenizer.from_pretrained(self.loj_en_model_name)\n        self.loj_en_model = MarianMTModel.from_pretrained(self.loj_en_model_name).to(self.device)\n\n    def translate_to_lojban(self, text: str, num_variants: int = 3) -> List[str]:\n        \"\"\"Translate English text to Lojban with multiple variants.\"\"\"\n        inputs = self.en_loj_tokenizer(text, return_tensors=\"pt\", padding=True).to(self.device)\n        \n        translations = []\n        beam_configs = [\n            {\"num_beams\": 5, \"length_penalty\": 1.0, \"no_repeat_ngram_size\": 2},\n            {\"num_beams\": 8, \"length_penalty\": 0.8, \"no_repeat_ngram_size\": 3},\n            {\"num_beams\": 4, \"length_penalty\": 1.2, \"no_repeat_ngram_size\": 2}\n        ]\n        \n        for config in beam_configs[:num_variants]:\n            outputs = self.en_loj_model.generate(\n                **inputs,\n                max_length=50,\n                early_stopping=True,\n                **config\n            )\n            translation = self.en_loj_tokenizer.decode(outputs[0], skip_special_tokens=True)\n            translations.append(translation)\n        \n        return list(set(translations))  # Remove duplicates\n\n    def translate_to_english(self, text: str) -> str:\n        \"\"\"Translate Lojban text back to English.\"\"\"\n        inputs = self.loj_en_tokenizer(text, return_tensors=\"pt\", padding=True).to(self.device)\n        \n        outputs = self.loj_en_model.generate(\n            **inputs,\n            max_length=50,\n            num_beams=5,\n            length_penalty=1.0,\n            no_repeat_ngram_size=2,\n            early_stopping=True\n        )\n        \n        return self.loj_en_tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    def round_trip_translate(self, text: str) -> Dict[str, List[str]]:\n        \"\"\"Perform round-trip translation: English -> Lojban -> English.\"\"\"\n        results = {\n            \"original\": text,\n            \"lojban_variants\": [],\n            \"back_translations\": []\n        }\n        \n        # Get Lojban translations\n        lojban_translations = self.translate_to_lojban(text)\n        results[\"lojban_variants\"] = lojban_translations\n        \n        # Translate each Lojban variant back to English\n        for lojban_text in lojban_translations:\n            back_translation = self.translate_to_english(lojban_text)\n            results[\"back_translations\"].append(back_translation)\n            \n        return results\n\ndef demonstrate_pipeline():\n    \"\"\"Demonstrate the translation pipeline with example sentences.\"\"\"\n    pipeline = TranslationPipeline()\n    \n    test_sentences = [\n        \"Hello, how are you?\",\n        \"The red book is on the big table\",\n        \"I really love learning Lojban\",\n        \"What time is it?\",\n        \"The weather is nice today\"\n    ]\n    \n    print(\"\\nRunning translation demonstrations:\")\n    print(\"=\" * 60)\n    \n    for sentence in test_sentences:\n        results = pipeline.round_trip_translate(sentence)\n        \n        print(f\"\\nOriginal English: {results['original']}\")\n        print(\"\\nLojban variants:\")\n        for i, variant in enumerate(results['lojban_variants'], 1):\n            print(f\"{i}. {variant}\")\n        \n        print(\"\\nBack translations:\")\n        for i, translation in enumerate(results['back_translations'], 1):\n            print(f\"{i}. {translation}\")\n        print(\"-\" * 60)\n\nif __name__ == \"__main__\":\n    demonstrate_pipeline()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T06:45:43.132642Z","iopub.execute_input":"2024-10-25T06:45:43.133132Z","iopub.status.idle":"2024-10-25T06:45:52.878540Z","shell.execute_reply.started":"2024-10-25T06:45:43.133082Z","shell.execute_reply":"2024-10-25T06:45:52.877592Z"},"trusted":true},"execution_count":null,"outputs":[]}]}