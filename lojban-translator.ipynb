{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"HF_TOKEN\")\nfrom huggingface_hub import login\nlogin(token=f\"{secret_value_0}\",write_permission=True)  # Enter your HF token when prompted\n!pip install sacrebleu pandas tqdm","metadata":{"execution":{"iopub.status.busy":"2024-10-25T05:39:29.364838Z","iopub.execute_input":"2024-10-25T05:39:29.365561Z","iopub.status.idle":"2024-10-25T05:39:41.181933Z","shell.execute_reply.started":"2024-10-25T05:39:29.365513Z","shell.execute_reply":"2024-10-25T05:39:41.180871Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import MarianMTModel, MarianTokenizer\nfrom tqdm.auto import tqdm\nimport pandas as pd\nfrom sacrebleu.metrics import BLEU\nfrom typing import List, Dict, Tuple\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\nclass LojbanTranslationEvaluator:\n    def __init__(self):\n        self.model_name = \"woctordho/lojban-translation\"\n        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n        self.bleu = BLEU()\n        \n        # Lojban normalization rules\n        self.normalization_rules = {\n            'lo lo': 'le',\n            'la la': 'le',\n            'zvati': 'cpana',  # Common spatial relationship equivalents\n            'se bangu': 'bangu',  # Language usage equivalents\n        }\n        \n    def normalize_lojban(self, text: str) -> str:\n        \"\"\"Enhanced Lojban text normalization.\"\"\"\n        text = re.sub(r'\\s+', ' ', text.strip())\n        text = re.sub(r'\\.+', '.', text)  # Normalize multiple dots\n        text = re.sub(r'\\s*\\.\\s*', ' . ', text)  # Normalize spacing around dots\n        \n        # Apply normalization rules\n        for old, new in self.normalization_rules.items():\n            text = text.replace(old, new)\n            \n        # Remove unnecessary particles in certain contexts\n        text = re.sub(r'\\.i\\s+', '', text)  # Remove .i at start\n        \n        return text.strip()\n\n    def semantic_similarity(self, translation: str, reference: str) -> float:\n        \"\"\"Calculate semantic similarity between translation and reference.\"\"\"\n        trans_words = set(translation.split())\n        ref_words = set(reference.split())\n        \n        intersection = len(trans_words.intersection(ref_words))\n        union = len(trans_words.union(ref_words))\n        \n        return intersection / union if union > 0 else 0.0\n\n    def load_test_data(self) -> List[Dict[str, str]]:\n        \"\"\"Load test data with multiple reference translations.\"\"\"\n        return [\n            {\n                \"english\": \"Hello, how are you?\",\n                \"references\": [\"coi do mo\", \"coi .i do mo\", \"coi pei\"],\n                \"category\": \"greetings\",\n                \"complexity\": \"simple\"\n            },\n            {\n                \"english\": \"The red book is on the big table\",\n                \"references\": [\"le xunre cukta cu cpana le barda jubme\", \n                             \"lo xunre cukta cu zvati lo barda jubme\"],\n                \"category\": \"spatial\",\n                \"complexity\": \"complex\"\n            },\n            {\n                \"english\": \"I really love learning Lojban\",\n                \"references\": [\"mi mutce nelci lo nu cilre la lojban\",\n                             \"mi nelci lo nu cilre la lojban\"],\n                \"category\": \"emotions\",\n                \"complexity\": \"complex\"\n            },\n            {\n                \"english\": \"What time is it?\",\n                \"references\": [\"ma tcika\", \"lo tcika cu mo\"],\n                \"category\": \"questions\",\n                \"complexity\": \"simple\"\n            },\n            {\n                \"english\": \"The weather is nice today\",\n                \"references\": [\"le temci cu xamgu ca lo cabdei\",\n                             \"lo temci be ca lo cabdei cu xamgu\"],\n                \"category\": \"descriptions\",\n                \"complexity\": \"medium\"\n            }\n        ]\n\n    def evaluate_translation(self, \n                           translation: str, \n                           references: List[str], \n                           category: str) -> Dict[str, float]:\n        \"\"\"Evaluate a single translation against multiple references.\"\"\"\n        # Normalize all texts\n        norm_translation = self.normalize_lojban(translation)\n        norm_references = [self.normalize_lojban(ref) for ref in references]\n        \n        # Calculate metrics\n        metrics = {\n            \"bleu\": max(self.bleu.corpus_score([norm_translation], [[ref]]).score \n                       for ref in norm_references),\n            \"exact_match\": any(norm_translation == ref for ref in norm_references),\n            \"semantic_similarity\": max(self.semantic_similarity(norm_translation, ref) \n                                    for ref in norm_references),\n            \"valid_lojban\": bool(re.search(r'\\b(cu|lo|le|la)\\b', translation))\n        }\n        \n        return metrics\n\n    def translate_text(self, \n                      model: MarianMTModel, \n                      tokenizer: MarianTokenizer, \n                      text: str) -> List[str]:\n        \"\"\"Generate translation variants using different beam search parameters.\"\"\"\n        inputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(self.device)\n        \n        # Generate with different beam widths\n        translations = []\n        \n        # Standard beam search\n        outputs = model.generate(\n            **inputs,\n            max_length=50,\n            num_beams=5,\n            length_penalty=1.0,\n            no_repeat_ngram_size=2,\n            early_stopping=True\n        )\n        translations.append(tokenizer.decode(outputs[0], skip_special_tokens=True))\n        \n        # Wider beam search\n        outputs = model.generate(\n            **inputs,\n            max_length=50,\n            num_beams=8,\n            length_penalty=0.8,\n            no_repeat_ngram_size=3,\n            early_stopping=True\n        )\n        translations.append(tokenizer.decode(outputs[0], skip_special_tokens=True))\n        \n        # More conservative beam search\n        outputs = model.generate(\n            **inputs,\n            max_length=50,\n            num_beams=4,\n            length_penalty=1.2,\n            no_repeat_ngram_size=2,\n            early_stopping=True\n        )\n        translations.append(tokenizer.decode(outputs[0], skip_special_tokens=True))\n        \n        return list(set(translations))  # Remove duplicates\n\n    def run_evaluation(self) -> pd.DataFrame:\n        \"\"\"Run comprehensive evaluation.\"\"\"\n        print(\"Loading model...\")\n        model = MarianMTModel.from_pretrained(self.model_name).to(self.device)\n        tokenizer = MarianTokenizer.from_pretrained(self.model_name)\n        \n        results = []\n        test_data = self.load_test_data()\n        \n        print(\"Running translations...\")\n        for item in tqdm(test_data):\n            translations = self.translate_text(model, tokenizer, item[\"english\"])\n            \n            # Evaluate each variant\n            variant_metrics = []\n            for trans in translations:\n                metrics = self.evaluate_translation(\n                    trans, item[\"references\"], item[\"category\"])\n                variant_metrics.append(metrics)\n            \n            # Select best variant based on BLEU score\n            best_variant_idx = max(range(len(variant_metrics)), \n                                 key=lambda i: variant_metrics[i][\"bleu\"])\n            \n            results.append({\n                \"english\": item[\"english\"],\n                \"best_translation\": translations[best_variant_idx],\n                \"references\": item[\"references\"],\n                \"category\": item[\"category\"],\n                \"complexity\": item[\"complexity\"],\n                \"metrics\": variant_metrics[best_variant_idx],\n                \"all_variants\": translations\n            })\n        \n        return pd.DataFrame(results)\n\ndef main():\n    evaluator = LojbanTranslationEvaluator()\n    results = evaluator.run_evaluation()\n    \n    # Generate detailed report\n    print(\"\\nDetailed Translation Analysis:\")\n    print(\"=\" * 80)\n    \n    # Overall statistics\n    print(\"\\nOverall Performance:\")\n    avg_bleu = results[\"metrics\"].apply(lambda x: x[\"bleu\"]).mean()\n    avg_semantic = results[\"metrics\"].apply(lambda x: x[\"semantic_similarity\"]).mean()\n    print(f\"Average BLEU Score: {avg_bleu:.2f}\")\n    print(f\"Average Semantic Similarity: {avg_semantic:.2f}\")\n    \n    # Performance by category and complexity\n    print(\"\\nPerformance by Category:\")\n    for category in results[\"category\"].unique():\n        cat_results = results[results[\"category\"] == category]\n        avg_cat_bleu = cat_results[\"metrics\"].apply(lambda x: x[\"bleu\"]).mean()\n        print(f\"{category:15} - BLEU: {avg_cat_bleu:.2f}\")\n    \n    print(\"\\nPerformance by Complexity:\")\n    for complexity in results[\"complexity\"].unique():\n        comp_results = results[results[\"complexity\"] == complexity]\n        avg_comp_bleu = comp_results[\"metrics\"].apply(lambda x: x[\"bleu\"]).mean()\n        print(f\"{complexity:15} - BLEU: {avg_comp_bleu:.2f}\")\n    \n    # Detailed examples\n    print(\"\\nDetailed Examples:\")\n    for _, row in results.iterrows():\n        print(f\"\\nCategory: {row['category']} (Complexity: {row['complexity']})\")\n        print(f\"English: {row['english']}\")\n        print(\"Translation Variants:\")\n        for i, variant in enumerate(row['all_variants'], 1):\n            print(f\"{i}. {variant}\")\n        print(\"References:\")\n        for i, ref in enumerate(row['references'], 1):\n            print(f\"{i}. {ref}\")\n        print(\"-\" * 40)\n    \n    # Save results\n    results.to_csv(\"lojban_translation_detailed_analysis.csv\", index=False)\n    print(\"\\nDetailed results saved to lojban_translation_detailed_analysis.csv\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"execution":{"iopub.status.busy":"2024-10-25T05:50:17.223611Z","iopub.execute_input":"2024-10-25T05:50:17.223990Z","iopub.status.idle":"2024-10-25T05:50:22.636372Z","shell.execute_reply.started":"2024-10-25T05:50:17.223950Z","shell.execute_reply":"2024-10-25T05:50:22.635437Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Loading model...\nRunning translations...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"014ac9ef1dc648a6ac8649030327fbdb"}},"metadata":{}},{"name":"stdout","text":"\nDetailed Translation Analysis:\n================================================================================\n\nOverall Performance:\nAverage BLEU Score: 45.85\nAverage Semantic Similarity: 0.56\n\nPerformance by Category:\ngreetings       - BLEU: 46.31\nspatial         - BLEU: 100.00\nemotions        - BLEU: 61.05\nquestions       - BLEU: 0.00\ndescriptions    - BLEU: 21.87\n\nPerformance by Complexity:\nsimple          - BLEU: 23.15\ncomplex         - BLEU: 80.52\nmedium          - BLEU: 21.87\n\nDetailed Examples:\n\nCategory: greetings (Complexity: simple)\nEnglish: Hello, how are you?\nTranslation Variants:\n1. coi do pei\n2. coi pei pei\n3. coi .i pei\nReferences:\n1. coi do mo\n2. coi .i do mo\n3. coi pei\n----------------------------------------\n\nCategory: spatial (Complexity: complex)\nEnglish: The red book is on the big table\nTranslation Variants:\n1. le xunre cukta cu zvati lo barda jubme\n2. lo xunre cukta cu zvati lo barda jubme\nReferences:\n1. le xunre cukta cu cpana le barda jubme\n2. lo xunre cukta cu zvati lo barda jubme\n----------------------------------------\n\nCategory: emotions (Complexity: complex)\nEnglish: I really love learning Lojban\nTranslation Variants:\n1. mi je'a prami lo ka se jban\n2. mi je prami nelci lo nu cilre la lojban\n3. mi je'a prami lo ka ca'o se jban\nReferences:\n1. mi mutce nelci lo nu cilre la lojban\n2. mi nelci lo nu cilre la lojban\n----------------------------------------\n\nCategory: questions (Complexity: simple)\nEnglish: What time is it?\nTranslation Variants:\n1. ca ti mo\nReferences:\n1. ma tcika\n2. lo tcika cu mo\n----------------------------------------\n\nCategory: descriptions (Complexity: medium)\nEnglish: The weather is nice today\nTranslation Variants:\n1. lo cabdei cu nenri\nReferences:\n1. le temci cu xamgu ca lo cabdei\n2. lo temci be ca lo cabdei cu xamgu\n----------------------------------------\n\nDetailed results saved to lojban_translation_detailed_analysis.csv\n","output_type":"stream"}]}]}